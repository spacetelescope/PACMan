{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pacman_classes\n",
    "from utils import tokenizer\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_cycle = '25'\n",
    "proposal_training_data_dir = f'../training_data/Cycle{proposal_cycle}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read in the hand classifications for each proposal and then match them with their training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proposal_num</th>\n",
       "      <th>hand_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>stellar physics and stellar types</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>galaxies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>stellar physics and stellar types</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics and stellar types</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>stellar populations and the interstellar medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proposal_num                              hand_classification\n",
       "0             1                stellar physics and stellar types\n",
       "1             2                                         galaxies\n",
       "2             3                stellar physics and stellar types\n",
       "3             4                stellar physics and stellar types\n",
       "4             5  stellar populations and the interstellar medium"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_classifications = pd.read_csv(f'{proposal_training_data_dir}/cycle_{proposal_cycle}_hand_classifications.txt')\n",
    "proposal_classifications.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of files from the training data for the specified proposal cycle.\n",
    "In order to match these files to their new classifications using updated science cataegories, we need to parse their proposal numbers from the filename, then sort them by proposal number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = glob.glob(f\"{proposal_training_data_dir}/*training.txt\") \n",
    "proposal_numbers = [int(val.split('/')[-1].split('_')[0]) for val in flist]\n",
    "flist_and_pnum = list(zip(flist, proposal_numbers))\n",
    "flist_and_pnum.sort(key=lambda val: val[1])\n",
    "flist_sorted, proposal_num = list(zip(*flist_and_pnum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine the sorted proposal list with their classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of missing proposals generated from the pdf abstract list: 292\n",
      "Total number of missing proposals generated using the scraped proposal texts: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tking/miniconda3/envs/pacman_osx-3.8/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "hand_classified_null = proposal_classifications[proposal_classifications['hand_classification'].isnull()]\n",
    "print(f\"Total number of missing proposals generated from the pdf abstract list: {len(hand_classified_null)}\")\n",
    "a = np.ediff1d(proposal_num)\n",
    "idx = list(map(int, np.where(a>1)[0]))\n",
    "missing_proposals = [proposal_num[val]+1 for val in idx]\n",
    "print(f\"Total number of missing proposals generated using the scraped proposal texts: {len(missing_proposals)}\")\n",
    "\n",
    "# Generate a new columnn to store the filenames and initialize it with NaNs\n",
    "proposal_classifications['fname'] = [np.nan]*len(proposal_classifications)\n",
    "\n",
    "# Loop through each proposal and update the dataframe with the filename\n",
    "for num, fname in zip(proposal_num, flist_sorted):\n",
    "    proposal_classifications['fname'].loc[num-1] = fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001_training.txt 1 stellar physics and stellar types\n",
      "0002_training.txt 2 galaxies\n",
      "0003_training.txt 3 stellar physics and stellar types\n",
      "0004_training.txt 4 stellar physics and stellar types\n",
      "0005_training.txt 5 stellar populations and the interstellar medium\n",
      "0006_training.txt 6 stellar populations and the interstellar medium\n",
      "0007_training.txt 7 galaxies\n",
      "0008_training.txt 8 stellar physics and stellar types\n",
      "0009_training.txt 9 intergalactic medium and the circumgalactic medium\n",
      "0010_training.txt 10 large scale structure of the universe\n",
      "0011_training.txt 11 stellar physics and stellar types\n",
      "0012_training.txt 12 galaxies\n",
      "0013_training.txt 13 stellar populations and the interstellar medium\n",
      "0014_training.txt 14 stellar populations and the interstellar medium\n",
      "0015_training.txt 15 large scale structure of the universe\n",
      "0016_training.txt 16 intergalactic medium and the circumgalactic medium\n",
      "0017_training.txt 17 supermassive black holes and active galaxies\n",
      "nan 18 nan\n",
      "0019_training.txt 19 galaxies\n"
     ]
    }
   ],
   "source": [
    "for i, (f, proposal_num, cls) in enumerate(zip(proposal_classifications['fname'],proposal_classifications['proposal_num'],proposal_classifications['hand_classification'])):\n",
    "    try:\n",
    "        print(f.split('/')[-1], proposal_num, cls)\n",
    "    except AttributeError as e:\n",
    "        print(f, proposal_num, cls)\n",
    "    if i+1==19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to generate a transformation that maps our science categories to a unique integer in the set {0,1,..,$N_{cat}$-1}.\n",
    "To do this we will use the `LabelEncoder` class in scikit-learn, but before doing so we need to filter out any row containing NaN. Once we've generated the encoding, we add a column to the DataFrame containing the encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The identified classes are:\n",
      "exoplanets and exoplanet formation\n",
      "galaxies\n",
      "intergalactic medium and the circumgalactic medium\n",
      "large scale structure of the universe\n",
      "solar system astronomy\n",
      "stellar physics and stellar types\n",
      "stellar populations and the interstellar medium\n",
      "supermassive black holes and active galaxies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-384d8265f04a>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['encoded_classification'] = encoded_values\n"
     ]
    }
   ],
   "source": [
    "# Drop any rows that have nan\n",
    "final_df = proposal_classifications.dropna()\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(final_df['hand_classification'])\n",
    "nl = '\\n'\n",
    "print(f\"The identified classes are:\\n{nl.join(encoder.classes_)}\")\n",
    "encoded_values = encoder.transform(final_df['hand_classification'])\n",
    "final_df['encoded_classification'] = encoded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proposal_num</th>\n",
       "      <th>hand_classification</th>\n",
       "      <th>fname</th>\n",
       "      <th>encoded_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>stellar physics and stellar types</td>\n",
       "      <td>../training_data/Cycle25/0001_training.txt</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>galaxies</td>\n",
       "      <td>../training_data/Cycle25/0002_training.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>stellar physics and stellar types</td>\n",
       "      <td>../training_data/Cycle25/0003_training.txt</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics and stellar types</td>\n",
       "      <td>../training_data/Cycle25/0004_training.txt</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>stellar populations and the interstellar medium</td>\n",
       "      <td>../training_data/Cycle25/0005_training.txt</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proposal_num                              hand_classification  \\\n",
       "0             1                stellar physics and stellar types   \n",
       "1             2                                         galaxies   \n",
       "2             3                stellar physics and stellar types   \n",
       "3             4                stellar physics and stellar types   \n",
       "4             5  stellar populations and the interstellar medium   \n",
       "\n",
       "                                        fname  encoded_classification  \n",
       "0  ../training_data/Cycle25/0001_training.txt                       5  \n",
       "1  ../training_data/Cycle25/0002_training.txt                       1  \n",
       "2  ../training_data/Cycle25/0003_training.txt                       5  \n",
       "3  ../training_data/Cycle25/0004_training.txt                       5  \n",
       "4  ../training_data/Cycle25/0005_training.txt                       6  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a proper encoding for our hand classified proposals, we need to read in each file to extract the text. Once all the files have been processed, we merge the returned `text_df` with the `final_df` from above. This returns a dataframe containing everything we need for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8696cc15569d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPACManPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: preprocess() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "text_df = pacman_classes.read_in_dataset(flist=final_df['fname'].values, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dwarf galaxies were the first systems to form stars within the Universe. An understanding of their starformation histories (SFH) across cosmic time is therefore imperative for galaxy formation and evolution studies. In particular, understanding how the most metal-poor of these systems, blue compact dwarf (BCD) galaxies, remain chemically pristine despite long periods of moderate SF with a recent burst remains a challenge. We are also yet to understand how starbursting BCDs and quiescent dwarf irregulars (dIrrs) show similar SFHs, despite an ord'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['text'][1][:550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hubble space telescope hst instrumental elucidate nature intriguing superluminous supernovae slsne e'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['cleaned_text'][0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proposal_num</th>\n",
       "      <th>hand_classification</th>\n",
       "      <th>fname</th>\n",
       "      <th>encoded_classification</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>/home/nmiles/PACMan_dist/training_data/trainin...</td>\n",
       "      <td>4</td>\n",
       "      <td>The Hubble Space Telescope (HST) has been inst...</td>\n",
       "      <td>hubble space telescope hst instrumental elucid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>/home/nmiles/PACMan_dist/training_data/trainin...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dwarf galaxies were the first systems to form ...</td>\n",
       "      <td>dwarf galaxy form star universe understanding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>stellar populations and the ism</td>\n",
       "      <td>/home/nmiles/PACMan_dist/training_data/trainin...</td>\n",
       "      <td>5</td>\n",
       "      <td>The Galactic stellar populations are moving th...</td>\n",
       "      <td>galactic stellar population interstellar mediu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>/home/nmiles/PACMan_dist/training_data/trainin...</td>\n",
       "      <td>4</td>\n",
       "      <td>We propose to compute state-of-the-art model a...</td>\n",
       "      <td>propose compute state art model atmosphere pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>stellar populations and the ism</td>\n",
       "      <td>/home/nmiles/PACMan_dist/training_data/trainin...</td>\n",
       "      <td>5</td>\n",
       "      <td>Hypervelocity stars (HVS) are young stellar ob...</td>\n",
       "      <td>hypervelocity star hvs young stellar object ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proposal_num              hand_classification  \\\n",
       "0             1                  stellar physics   \n",
       "1             2             galaxies and the igm   \n",
       "2             3  stellar populations and the ism   \n",
       "3             4                  stellar physics   \n",
       "4             5  stellar populations and the ism   \n",
       "\n",
       "                                               fname  encoded_classification  \\\n",
       "0  /home/nmiles/PACMan_dist/training_data/trainin...                       4   \n",
       "1  /home/nmiles/PACMan_dist/training_data/trainin...                       0   \n",
       "2  /home/nmiles/PACMan_dist/training_data/trainin...                       5   \n",
       "3  /home/nmiles/PACMan_dist/training_data/trainin...                       4   \n",
       "4  /home/nmiles/PACMan_dist/training_data/trainin...                       5   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Hubble Space Telescope (HST) has been inst...   \n",
       "1  Dwarf galaxies were the first systems to form ...   \n",
       "2  The Galactic stellar populations are moving th...   \n",
       "3  We propose to compute state-of-the-art model a...   \n",
       "4  Hypervelocity stars (HVS) are young stellar ob...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  hubble space telescope hst instrumental elucid...  \n",
       "1  dwarf galaxy form star universe understanding ...  \n",
       "2  galactic stellar population interstellar mediu...  \n",
       "3  propose compute state art model atmosphere pho...  \n",
       "4  hypervelocity star hvs young stellar object ex...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.merge(final_df, text_df, on='fname')\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in our pipeline will be to generate a vocabulary using the entire corpus, then we will turn our documents into vectors using the term frequency inverse document frequency method (tf-idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    use_idf=True,\n",
    "    norm='l2',\n",
    "    ngram_range=(1, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7244c0b94963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidf_vectorizer_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer_vectors = tfidf_vect.fit_transform(combined_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ce832510aa73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "combined_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_vectorizer_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4361418937e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirst_vector_tfidfvectorizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfidf_vectorizer_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#place tf-idf values in a pandas data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_vector_tfidfvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfidf_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tfidf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tfidf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf_vectorizer_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[1]\n",
    "\n",
    "#place tf-idf values in a pandas data frame\n",
    "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vect.get_feature_names(), columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf = Pipeline(\n",
    "    [('vect', tfidf_vect),\n",
    "     ('clf', MultinomialNB(alpha=0.05))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb_tfidf = Pipeline(\n",
    "    [('vect', tfidf_vect),\n",
    "    ('clf', ComplementNB(alpha=0.05))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b7f6ab869c42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoded_classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "nb_tfidf.fit(combined_df['cleaned_text'], combined_df['encoded_classification'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we trained a NB classifier on the cleaned text and the encoded classifications. The next step is to read in all of training data for cycle 24 and make predictions using the trained classifier. Once we make our predictions, we need to compare them to the truth set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-32cdf6ee9c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnb_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoded_classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "cnb_tfidf.fit(combined_df['cleaned_text'], combined_df['encoded_classification'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the fitted classifiers to disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_tfidf_cls.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(nb_tfidf, 'nb_tfidf_cls.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_in_cls = load('nb_tfidf_cls.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
       "                ('clf', MultinomialNB(alpha=0.05))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_in_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/nmiles/PACMan_dist/training_data/training_corpus_cy24/cycle_24_hand_classifications.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ce51f14ee269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproposal_classifications_cy24\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/nmiles/PACMan_dist/training_data/training_corpus_cy24/cycle_24_hand_classifications.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mproposal_classifications_cy24_nonans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposal_classifications_cy24\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_classifications_cy24_nonans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoded_values_cy24\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal_classifications_cy24_nonans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hand_classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mproposal_classifications_cy24_nonans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'true_classification_encoded'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_values_cy24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pacman_osx-3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pacman_osx-3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pacman_osx-3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pacman_osx-3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pacman_osx-3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pacman_osx-3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pacman_osx-3.8/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/nmiles/PACMan_dist/training_data/training_corpus_cy24/cycle_24_hand_classifications.txt'"
     ]
    }
   ],
   "source": [
    "proposal_classifications_cy24 = pd.read_csv('/Users/nmiles/PACMan_dist/training_data/training_corpus_cy24/cycle_24_hand_classifications.txt')\n",
    "proposal_classifications_cy24_nonans = proposal_classifications_cy24.dropna()\n",
    "print(proposal_classifications_cy24_nonans.head())\n",
    "encoded_values_cy24 = encoder.transform(proposal_classifications_cy24_nonans['hand_classification'])\n",
    "proposal_classifications_cy24_nonans['true_classification_encoded'] = encoded_values_cy24\n",
    "print(proposal_classifications_cy24_nonans.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6d7c8fe49f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mflist_and_pnum_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflist_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_numbers_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflist_and_pnum_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mflist_test_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_num_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflist_and_pnum_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "flist_test = glob.glob(f\"/Users/nmiles/PACMan_dist/training_data/training_corpus_cy24/*training.txt\") \n",
    "proposal_numbers_test = [int(val.split('/')[-1].split('_')[0]) for val in flist_test]\n",
    "flist_and_pnum_test = list(zip(flist_test, proposal_numbers_test))\n",
    "flist_and_pnum_test.sort(key=lambda val: val[1])\n",
    "flist_test_sorted, proposal_num_test = list(zip(*flist_and_pnum_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO [pacman2020.read_in_dataset:177] Reading in 1093 proposals...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 16min  4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO [pacman2020.read_in_dataset:204] Total time for preprocessing: 16.087\n"
     ]
    }
   ],
   "source": [
    "test_text_df = pacman2020.read_in_dataset(flist=flist_test_sorted, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PG1159 stars are H-deficient (pre-) white dwar...</td>\n",
       "      <td>pg1159 star h deficient pre- white dwarf surfa...</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On December 7, 2015 JAXA`s Akatsuki/Venus Clim...</td>\n",
       "      <td>december jaxa`s akatsuki venus climate orbiter...</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The vacuum ultraviolet (UV) contains many stro...</td>\n",
       "      <td>vacuum ultraviolet uv contain strong transitio...</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most outstanding issues in exoplane...</td>\n",
       "      <td>outstanding exoplanet characterization underst...</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WFC3 extends to the infrared the capacity of H...</td>\n",
       "      <td>wfc3 extend infrared capacity hst resolve red ...</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  PG1159 stars are H-deficient (pre-) white dwar...   \n",
       "1  On December 7, 2015 JAXA`s Akatsuki/Venus Clim...   \n",
       "2  The vacuum ultraviolet (UV) contains many stro...   \n",
       "3  One of the most outstanding issues in exoplane...   \n",
       "4  WFC3 extends to the infrared the capacity of H...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  pg1159 star h deficient pre- white dwarf surfa...   \n",
       "1  december jaxa`s akatsuki venus climate orbiter...   \n",
       "2  vacuum ultraviolet uv contain strong transitio...   \n",
       "3  outstanding exoplanet characterization underst...   \n",
       "4  wfc3 extend infrared capacity hst resolve red ...   \n",
       "\n",
       "                                               fname  \n",
       "0  /Users/nmiles/PACMan_dist/training_data/traini...  \n",
       "1  /Users/nmiles/PACMan_dist/training_data/traini...  \n",
       "2  /Users/nmiles/PACMan_dist/training_data/traini...  \n",
       "3  /Users/nmiles/PACMan_dist/training_data/traini...  \n",
       "4  /Users/nmiles/PACMan_dist/training_data/traini...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = read_in_cls.predict(test_text_df['cleaned_text'])\n",
    "nb_prediction_probabilities = nb_tfidf.predict_proba(test_text_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb_predictions = cnb_tfidf.predict(test_text_df['cleaned_text'])\n",
    "cnb_prediction_probabilities = nb_tfidf.predict(test_text_df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['galaxies and the igm', 'large scale structure of the universe',\n",
       "       'planets and planet formation', 'solar system', 'stellar physics',\n",
       "       'stellar populations and the ism',\n",
       "       'supermassive black holes and active galaxies'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: galaxies and the igm, probability: 0.04%\n",
      "class: large scale structure of the universe, probability: 0.09%\n",
      "class: planets and planet formation, probability: 61.60%\n",
      "class: solar system, probability: 37.29%\n",
      "class: stellar physics, probability: 0.71%\n",
      "class: stellar populations and the ism, probability: 0.19%\n",
      "class: supermassive black holes and active galaxies, probability: 0.08%\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(nb_prediction_probabilities[1]):\n",
    "    print(f\"class: {encoder.classes_[i]}, probability: {p:0.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = test_text_df.loc[:,['fname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df['proposal_num'] = proposal_num_test\n",
    "final_test_df['nb_encoded_classification'] = nb_predictions\n",
    "final_test_df['cnb_encoded_classification'] = cnb_predictions\n",
    "final_test_df['nb_classes'] = [encoder.classes_[val] for val in nb_predictions]\n",
    "final_test_df['cnb_classes'] = [encoder.classes_[val] for val in cnb_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>proposal_num</th>\n",
       "      <th>nb_encoded_classification</th>\n",
       "      <th>cnb_encoded_classification</th>\n",
       "      <th>nb_classes</th>\n",
       "      <th>cnb_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>large scale structure of the universe</td>\n",
       "      <td>large scale structure of the universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1109</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1093 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  fname  proposal_num  \\\n",
       "0     /Users/nmiles/PACMan_dist/training_data/traini...             1   \n",
       "1     /Users/nmiles/PACMan_dist/training_data/traini...             7   \n",
       "2     /Users/nmiles/PACMan_dist/training_data/traini...            12   \n",
       "3     /Users/nmiles/PACMan_dist/training_data/traini...            13   \n",
       "4     /Users/nmiles/PACMan_dist/training_data/traini...            15   \n",
       "...                                                 ...           ...   \n",
       "1088  /Users/nmiles/PACMan_dist/training_data/traini...          1109   \n",
       "1089  /Users/nmiles/PACMan_dist/training_data/traini...          1110   \n",
       "1090  /Users/nmiles/PACMan_dist/training_data/traini...          1111   \n",
       "1091  /Users/nmiles/PACMan_dist/training_data/traini...          1112   \n",
       "1092  /Users/nmiles/PACMan_dist/training_data/traini...          1113   \n",
       "\n",
       "      nb_encoded_classification  cnb_encoded_classification  \\\n",
       "0                             4                           4   \n",
       "1                             2                           2   \n",
       "2                             4                           4   \n",
       "3                             2                           2   \n",
       "4                             1                           1   \n",
       "...                         ...                         ...   \n",
       "1088                          4                           4   \n",
       "1089                          2                           2   \n",
       "1090                          0                           0   \n",
       "1091                          0                           0   \n",
       "1092                          0                           0   \n",
       "\n",
       "                                 nb_classes  \\\n",
       "0                           stellar physics   \n",
       "1              planets and planet formation   \n",
       "2                           stellar physics   \n",
       "3              planets and planet formation   \n",
       "4     large scale structure of the universe   \n",
       "...                                     ...   \n",
       "1088                        stellar physics   \n",
       "1089           planets and planet formation   \n",
       "1090                   galaxies and the igm   \n",
       "1091                   galaxies and the igm   \n",
       "1092                   galaxies and the igm   \n",
       "\n",
       "                                cnb_classes  \n",
       "0                           stellar physics  \n",
       "1              planets and planet formation  \n",
       "2                           stellar physics  \n",
       "3              planets and planet formation  \n",
       "4     large scale structure of the universe  \n",
       "...                                     ...  \n",
       "1088                        stellar physics  \n",
       "1089           planets and planet formation  \n",
       "1090                   galaxies and the igm  \n",
       "1091                   galaxies and the igm  \n",
       "1092                   galaxies and the igm  \n",
       "\n",
       "[1093 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(proposal_classifications_cy24_nonans, final_test_df, on='proposal_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proposal_num</th>\n",
       "      <th>hand_classification</th>\n",
       "      <th>true_classification_encoded</th>\n",
       "      <th>fname</th>\n",
       "      <th>nb_encoded_classification</th>\n",
       "      <th>cnb_encoded_classification</th>\n",
       "      <th>nb_classes</th>\n",
       "      <th>cnb_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>4</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>solar system</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>4</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>2</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>large scale structure of the universe</td>\n",
       "      <td>large scale structure of the universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1109</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>4</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1110</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>2</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1111</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1112</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1113</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1093 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      proposal_num           hand_classification  true_classification_encoded  \\\n",
       "0                1               stellar physics                            4   \n",
       "1                7                  solar system                            3   \n",
       "2               12               stellar physics                            4   \n",
       "3               13  planets and planet formation                            2   \n",
       "4               15          galaxies and the igm                            0   \n",
       "...            ...                           ...                          ...   \n",
       "1088          1109               stellar physics                            4   \n",
       "1089          1110  planets and planet formation                            2   \n",
       "1090          1111          galaxies and the igm                            0   \n",
       "1091          1112          galaxies and the igm                            0   \n",
       "1092          1113          galaxies and the igm                            0   \n",
       "\n",
       "                                                  fname  \\\n",
       "0     /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "1     /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "2     /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "3     /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "4     /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "...                                                 ...   \n",
       "1088  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "1089  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "1090  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "1091  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "1092  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "\n",
       "      nb_encoded_classification  cnb_encoded_classification  \\\n",
       "0                             4                           4   \n",
       "1                             2                           2   \n",
       "2                             4                           4   \n",
       "3                             2                           2   \n",
       "4                             1                           1   \n",
       "...                         ...                         ...   \n",
       "1088                          4                           4   \n",
       "1089                          2                           2   \n",
       "1090                          0                           0   \n",
       "1091                          0                           0   \n",
       "1092                          0                           0   \n",
       "\n",
       "                                 nb_classes  \\\n",
       "0                           stellar physics   \n",
       "1              planets and planet formation   \n",
       "2                           stellar physics   \n",
       "3              planets and planet formation   \n",
       "4     large scale structure of the universe   \n",
       "...                                     ...   \n",
       "1088                        stellar physics   \n",
       "1089           planets and planet formation   \n",
       "1090                   galaxies and the igm   \n",
       "1091                   galaxies and the igm   \n",
       "1092                   galaxies and the igm   \n",
       "\n",
       "                                cnb_classes  \n",
       "0                           stellar physics  \n",
       "1              planets and planet formation  \n",
       "2                           stellar physics  \n",
       "3              planets and planet formation  \n",
       "4     large scale structure of the universe  \n",
       "...                                     ...  \n",
       "1088                        stellar physics  \n",
       "1089           planets and planet formation  \n",
       "1090                   galaxies and the igm  \n",
       "1091                   galaxies and the igm  \n",
       "1092                   galaxies and the igm  \n",
       "\n",
       "[1093 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proposal_num</th>\n",
       "      <th>hand_classification</th>\n",
       "      <th>true_classification_encoded</th>\n",
       "      <th>fname</th>\n",
       "      <th>nb_encoded_classification</th>\n",
       "      <th>cnb_encoded_classification</th>\n",
       "      <th>nb_classes</th>\n",
       "      <th>cnb_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>4</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>solar system</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>4</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>2</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>large scale structure of the universe</td>\n",
       "      <td>large scale structure of the universe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proposal_num           hand_classification  true_classification_encoded  \\\n",
       "0             1               stellar physics                            4   \n",
       "1             7                  solar system                            3   \n",
       "2            12               stellar physics                            4   \n",
       "3            13  planets and planet formation                            2   \n",
       "4            15          galaxies and the igm                            0   \n",
       "\n",
       "                                               fname  \\\n",
       "0  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "1  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "2  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "3  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "4  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "\n",
       "   nb_encoded_classification  cnb_encoded_classification  \\\n",
       "0                          4                           4   \n",
       "1                          2                           2   \n",
       "2                          4                           4   \n",
       "3                          2                           2   \n",
       "4                          1                           1   \n",
       "\n",
       "                              nb_classes  \\\n",
       "0                        stellar physics   \n",
       "1           planets and planet formation   \n",
       "2                        stellar physics   \n",
       "3           planets and planet formation   \n",
       "4  large scale structure of the universe   \n",
       "\n",
       "                             cnb_classes  \n",
       "0                        stellar physics  \n",
       "1           planets and planet formation  \n",
       "2                        stellar physics  \n",
       "3           planets and planet formation  \n",
       "4  large scale structure of the universe  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "galaxies and the igm: 0.00%\n",
      "large scale structure of the universe: 0.00%\n",
      "planets and planet formation: 0.00%\n",
      "solar system: 0.00%\n",
      "stellar physics: 99.65%\n",
      "stellar populations and the ism: 0.34%\n",
      "supermassive black holes and active galaxies: 0.00%\n"
     ]
    }
   ],
   "source": [
    "for i, val in enumerate(nb_prediction_probabilities[0]):\n",
    "    print(f\"{encoder.classes_[i]}: {val:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = defaultdict(list)\n",
    "for i, row in merged_df.iterrows():\n",
    "    data_out['fname'].append(row['fname'])\n",
    "    data_out['nb_encoded_classification'].append(row['nb_encoded_classification'])\n",
    "    data_out['nb_classes'].append(row['nb_classes'])\n",
    "    data_out['hand_classification'].append(row['hand_classification'])\n",
    "    data_out['hand_encoded_classification'].append(row['true_classification_encoded'])\n",
    "    for j, class_prob in enumerate(nb_prediction_probabilities[i]):\n",
    "        data_out[f\"{encoder.classes_[j].replace(' ','_')}_prob\"].append(class_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>nb_encoded_classification</th>\n",
       "      <th>nb_classes</th>\n",
       "      <th>hand_classification</th>\n",
       "      <th>hand_encoded_classification</th>\n",
       "      <th>galaxies_and_the_igm_prob</th>\n",
       "      <th>large_scale_structure_of_the_universe_prob</th>\n",
       "      <th>planets_and_planet_formation_prob</th>\n",
       "      <th>solar_system_prob</th>\n",
       "      <th>stellar_physics_prob</th>\n",
       "      <th>stellar_populations_and_the_ism_prob</th>\n",
       "      <th>supermassive_black_holes_and_active_galaxies_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>4</td>\n",
       "      <td>5.029069e-06</td>\n",
       "      <td>2.659886e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>6.907907e-06</td>\n",
       "      <td>9.965369e-01</td>\n",
       "      <td>3.439741e-03</td>\n",
       "      <td>1.297075e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>solar system</td>\n",
       "      <td>3</td>\n",
       "      <td>4.342200e-04</td>\n",
       "      <td>9.483614e-04</td>\n",
       "      <td>0.615979</td>\n",
       "      <td>3.729015e-01</td>\n",
       "      <td>7.077454e-03</td>\n",
       "      <td>1.869559e-03</td>\n",
       "      <td>7.896306e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>4</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>stellar physics</td>\n",
       "      <td>4</td>\n",
       "      <td>6.921021e-05</td>\n",
       "      <td>1.004414e-06</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>7.687057e-06</td>\n",
       "      <td>9.991847e-01</td>\n",
       "      <td>5.347413e-04</td>\n",
       "      <td>2.591507e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>2</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>planets and planet formation</td>\n",
       "      <td>2</td>\n",
       "      <td>2.686037e-10</td>\n",
       "      <td>8.159139e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.410443e-07</td>\n",
       "      <td>1.305470e-07</td>\n",
       "      <td>6.286491e-09</td>\n",
       "      <td>1.114522e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/nmiles/PACMan_dist/training_data/traini...</td>\n",
       "      <td>1</td>\n",
       "      <td>large scale structure of the universe</td>\n",
       "      <td>galaxies and the igm</td>\n",
       "      <td>0</td>\n",
       "      <td>2.823897e-02</td>\n",
       "      <td>9.190719e-01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.298953e-05</td>\n",
       "      <td>5.872466e-04</td>\n",
       "      <td>5.188218e-02</td>\n",
       "      <td>1.737468e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               fname  \\\n",
       "0  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "1  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "2  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "3  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "4  /Users/nmiles/PACMan_dist/training_data/traini...   \n",
       "\n",
       "   nb_encoded_classification                             nb_classes  \\\n",
       "0                          4                        stellar physics   \n",
       "1                          2           planets and planet formation   \n",
       "2                          4                        stellar physics   \n",
       "3                          2           planets and planet formation   \n",
       "4                          1  large scale structure of the universe   \n",
       "\n",
       "            hand_classification  hand_encoded_classification  \\\n",
       "0               stellar physics                            4   \n",
       "1                  solar system                            3   \n",
       "2               stellar physics                            4   \n",
       "3  planets and planet formation                            2   \n",
       "4          galaxies and the igm                            0   \n",
       "\n",
       "   galaxies_and_the_igm_prob  large_scale_structure_of_the_universe_prob  \\\n",
       "0               5.029069e-06                                2.659886e-06   \n",
       "1               4.342200e-04                                9.483614e-04   \n",
       "2               6.921021e-05                                1.004414e-06   \n",
       "3               2.686037e-10                                8.159139e-09   \n",
       "4               2.823897e-02                                9.190719e-01   \n",
       "\n",
       "   planets_and_planet_formation_prob  solar_system_prob  stellar_physics_prob  \\\n",
       "0                           0.000007       6.907907e-06          9.965369e-01   \n",
       "1                           0.615979       3.729015e-01          7.077454e-03   \n",
       "2                           0.000177       7.687057e-06          9.991847e-01   \n",
       "3                           1.000000       3.410443e-07          1.305470e-07   \n",
       "4                           0.000003       4.298953e-05          5.872466e-04   \n",
       "\n",
       "   stellar_populations_and_the_ism_prob  \\\n",
       "0                          3.439741e-03   \n",
       "1                          1.869559e-03   \n",
       "2                          5.347413e-04   \n",
       "3                          6.286491e-09   \n",
       "4                          5.188218e-02   \n",
       "\n",
       "   supermassive_black_holes_and_active_galaxies_prob  \n",
       "0                                       1.297075e-06  \n",
       "1                                       7.896306e-04  \n",
       "2                                       2.591507e-05  \n",
       "3                                       1.114522e-09  \n",
       "4                                       1.737468e-04  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "galaxies and the igm                            335\n",
       "stellar physics                                 261\n",
       "supermassive black holes and active galaxies    131\n",
       "planets and planet formation                    130\n",
       "stellar populations and the ism                 116\n",
       "solar system                                     60\n",
       "large scale structure of the universe            60\n",
       "Name: hand_classification, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hand_classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cycle_24_classification_results.txt', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test_df.loc[:,['proposal_num', 'classification']].to_csv('Cycle24_classification_predictions.txt', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to evaluate the performance of the classifier.\n",
    "\n",
    "We will do this in two ways:\n",
    "- Using the classification metrics in scikit-learn\n",
    "     - This will simply look to see how many times the most probable classification matched the true classification.\n",
    "- Computing them by hand using a custom metric\n",
    "    - Here we will count a proposal as correctly classified if the top two most probable classifications contains the true classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-598470f9c7d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'true_classification_encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_encoded_classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/astroconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    353\u001b[0m     return _average_binary_score(\n\u001b[1;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda3/lib/python3.7/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "roc = roc_auc_score(merged_df['true_classification_encoded'], merged_df['nb_encoded_classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                        galaxies and the igm       0.84      0.81      0.83       335\n",
      "       large scale structure of the universe       0.50      0.57      0.53        60\n",
      "                planets and planet formation       0.86      0.96      0.91       130\n",
      "                                solar system       0.98      0.80      0.88        60\n",
      "                             stellar physics       0.91      0.89      0.90       261\n",
      "             stellar populations and the ism       0.74      0.77      0.75       116\n",
      "supermassive black holes and active galaxies       0.89      0.92      0.90       131\n",
      "\n",
      "                                    accuracy                           0.84      1093\n",
      "                                   macro avg       0.82      0.82      0.82      1093\n",
      "                                weighted avg       0.85      0.84      0.84      1093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes Results\n",
    "print(classification_report(merged_df['true_classification_encoded'], merged_df['nb_encoded_classification'], target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                        galaxies and the igm       0.82      0.86      0.84       335\n",
      "       large scale structure of the universe       0.54      0.47      0.50        60\n",
      "                planets and planet formation       0.79      0.97      0.87       130\n",
      "                                solar system       0.98      0.70      0.82        60\n",
      "                             stellar physics       0.91      0.89      0.90       261\n",
      "             stellar populations and the ism       0.81      0.68      0.74       116\n",
      "supermassive black holes and active galaxies       0.89      0.92      0.91       131\n",
      "\n",
      "                                    accuracy                           0.84      1093\n",
      "                                   macro avg       0.82      0.78      0.79      1093\n",
      "                                weighted avg       0.84      0.84      0.83      1093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complement Naive Bayes Results\n",
    "print(classification_report(merged_df['true_classification_encoded'], merged_df['cnb_encoded_classification'], target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, row = next(df.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fname', 'nb_encoded_classification', 'nb_classes',\n",
       "       'hand_classification', 'hand_encoded_classification',\n",
       "       'galaxies_and_the_igm_prob',\n",
       "       'large_scale_structure_of_the_universe_prob',\n",
       "       'planets_and_planet_formation_prob', 'solar_system_prob',\n",
       "       'stellar_physics_prob', 'stellar_populations_and_the_ism_prob',\n",
       "       'supermassive_black_holes_and_active_galaxies_prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stellar_physics_prob', 'stellar_populations_and_the_ism_prob']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(row[row.index.str.contains('prob')].sort_values(ascending=False)[:2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_accuracy = 0\n",
    "custom_accuracy_dict = {}\n",
    "for c in encoder.classes_:\n",
    "    custom_accuracy_dict[c] = {}\n",
    "for key in custom_accuracy_dict.keys():\n",
    "    custom_accuracy_dict[key]['top'] = []\n",
    "    custom_accuracy_dict[key]['top_two'] = []\n",
    "    custom_accuracy_dict[key]['misclassified'] = []\n",
    "for num, row in df.iterrows():\n",
    "    hand_classification = row['hand_classification']\n",
    "#     print(hand_classification)\n",
    "    top_two = row[row.index.str.contains('prob')].sort_values(ascending=False)[:2]\n",
    "    categories = list(top_two.index)\n",
    "    categories = [val.replace('_prob','').replace('_',' ') for val in categories]\n",
    "    probabilites = list(top_two.values)\n",
    "    if hand_classification == categories[0]:\n",
    "        custom_accuracy_dict[hand_classification]['top'].append(1)\n",
    "        custom_accuracy +=1\n",
    "    elif hand_classification in categories:\n",
    "        custom_accuracy_dict[hand_classification]['top_two'].append(1)\n",
    "        custom_accuracy +=1\n",
    "    else:\n",
    "        custom_accuracy_dict[hand_classification]['misclassified'].append(1)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure all proposals are categorized as either `top`, `top_two`, or `misclassified`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.52%\n"
     ]
    }
   ],
   "source": [
    "acurracy = custom_accuracy/len(df)\n",
    "print(f\"{acurracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_numbers = df['hand_classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_numbers['galaxies and the igm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_results = {'misclassified':[], 'top_two':[], 'top':[]}\n",
    "index=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of galaxies and the igm proposals in top: 81.19%\n",
      "Total number of galaxies and the igm proposals in top_two: 14.63%\n",
      "Total number of galaxies and the igm proposals in misclassified: 4.18%\n",
      "Total number of large scale structure of the universe proposals in top: 56.67%\n",
      "Total number of large scale structure of the universe proposals in top_two: 30.00%\n",
      "Total number of large scale structure of the universe proposals in misclassified: 13.33%\n",
      "Total number of planets and planet formation proposals in top: 96.15%\n",
      "Total number of planets and planet formation proposals in top_two: 2.31%\n",
      "Total number of planets and planet formation proposals in misclassified: 1.54%\n",
      "Total number of solar system proposals in top: 80.00%\n",
      "Total number of solar system proposals in top_two: 13.33%\n",
      "Total number of solar system proposals in misclassified: 6.67%\n",
      "Total number of stellar physics proposals in top: 88.89%\n",
      "Total number of stellar physics proposals in top_two: 8.43%\n",
      "Total number of stellar physics proposals in misclassified: 2.68%\n",
      "Total number of stellar populations and the ism proposals in top: 76.72%\n",
      "Total number of stellar populations and the ism proposals in top_two: 16.38%\n",
      "Total number of stellar populations and the ism proposals in misclassified: 6.90%\n",
      "Total number of supermassive black holes and active galaxies proposals in top: 91.60%\n",
      "Total number of supermassive black holes and active galaxies proposals in top_two: 3.82%\n",
      "Total number of supermassive black holes and active galaxies proposals in misclassified: 4.58%\n"
     ]
    }
   ],
   "source": [
    "for cat in custom_accuracy_dict.keys():\n",
    "    index.append(cat)\n",
    "    for key in custom_accuracy_dict[cat].keys():\n",
    "        num_per_key = sum(custom_accuracy_dict[cat][key])\n",
    "        frac_of_dataset = num_per_key/proposal_numbers[cat]\n",
    "        computed_results[key].append(frac_of_dataset)\n",
    "        print(f\"Total number of {cat} proposals in {key}: {num_per_key/proposal_numbers[cat]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'misclassified': [0.041791044776119404,\n",
       "  0.13333333333333333,\n",
       "  0.015384615384615385,\n",
       "  0.06666666666666667,\n",
       "  0.02681992337164751,\n",
       "  0.06896551724137931,\n",
       "  0.04580152671755725],\n",
       " 'top_two': [0.14626865671641792,\n",
       "  0.3,\n",
       "  0.023076923076923078,\n",
       "  0.13333333333333333,\n",
       "  0.0842911877394636,\n",
       "  0.16379310344827586,\n",
       "  0.03816793893129771],\n",
       " 'top': [0.8119402985074626,\n",
       "  0.5666666666666667,\n",
       "  0.9615384615384616,\n",
       "  0.8,\n",
       "  0.8888888888888888,\n",
       "  0.7672413793103449,\n",
       "  0.916030534351145]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_results_df = pd.DataFrame(computed_results, index=index)\n",
    "computed_results_df = computed_results_df[['top','top_two','misclassified']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_results_df.plot.barh(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_accuracy/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(merged_df['true_classification_encoded'], merged_df['nb_encoded_classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(merged_df['true_classification_encoded'], merged_df['nb_encoded_classification'], encoder.classes_, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('confusion_matrix_test.png', format='png', dpi=300)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
