{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification\n",
    "\n",
    "The goal of this notebook is to walk through the machine learning step of the text classification process.\n",
    "\n",
    "1) Encoding\n",
    "\n",
    "2) Partitioning the dataset into distinct subgroups\n",
    "\n",
    "3) Vectorization (Term Frequency Inverse Document Frequency (TF-IDF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('/Users/nmiles/PACMan_dist/')\n",
    "\n",
    "\n",
    "from astropy.visualization import ImageNormalize, LinearStretch, ZScaleInterval\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.tokenizer import PACManTokenizer\n",
    "import pacman2020\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_category_label(fname):\n",
    "    flabel = fname.replace('_training.txt','_Scientific_Category.txt')\n",
    "    with open(flabel, 'r') as fobj:\n",
    "        lines = fobj.readlines()\n",
    "    print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy22 = '/Users/nmiles/PACMan_dist/proposal_data/Cy22_Proposals_txt/'\n",
    "cy23 = '/Users/nmiles/PACMan_dist/proposal_data/Cy23_Proposals_txt'\n",
    "cy24 = '/Users/nmiles/PACMan_dist/proposal_data/Cy24_Proposals_txt'\n",
    "cy25 = '/Users/nmiles/PACMan_dist/proposal_data/Cy25_Proposals_txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/Users/nmiles/PACMan_dist/proposal_data/Cy25_proposals_txt/training_corpus/0001_training.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_category_label(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman = PACManTokenizer()\n",
    "pacman.get_stop_words(\n",
    "        fname='/Users/nmiles/PACMan_dist/libs/stopwords.txt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, cleaned_text, tokens = pacman.run_tokenization(fname=fname, N=20, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[:650])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist_text = glob.glob(f\"{cy25}/training_corpus/*training.txt\")\n",
    "flist_label = glob.glob(f\"{cy25}/training_corpus/*_Scientific_Category.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, data = pacman2020.read_in_dataset(flist=flist_text, parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train_df['category'].value_counts()\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "categories.plot.barh(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_subset(df, categories=[]):\n",
    "    subsets = {}\n",
    "    for category in categories:\n",
    "        data = df[df['category'] == category].iloc[:150,:]\n",
    "        subsets[category] = data\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = create_balanced_subset(train_df, categories=np.unique(train_df['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(len(subsets[key])) for key in subsets.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['category'].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['category_id'] = train_df['category'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_df_train = train_df[['category','category_id']]\n",
    "category_to_id_train = dict(category_id_df_train.values)\n",
    "id_to_category_train = dict(category_id_df_train[['category_id', 'category']].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_category_test[0] = 'stellar populations and the ism'\n",
    "id_to_category_test[1] = id_to_category_test[1].lower() \n",
    "id_to_category_test[2] = id_to_category_test[2].lower()\n",
    "id_to_category_test[3] = 'planets and planet formation'\n",
    "id_to_category_test[4] = 'galaxies and the igm'\n",
    "id_to_category_test[5] = 'large scale structure of the universe'\n",
    "id_to_category_test[6] = 'supermassive black holes and active galaxies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_category_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(max_features=10000,\n",
    "#                              tokenizer=pacman2020.spacy_tokenizer,\n",
    "#                              analyzer='word',\n",
    "                             stop_words='english',\n",
    "                             use_idf=True,\n",
    "                             norm='l2',\n",
    "                             ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features=10000, tokenizer=pacman2020.spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(train_df['text'], train_df['category_id'], test_size=0.2, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = count_vect.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_vectors=tfidf_vect.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0]\n",
    " \n",
    "# place tf-idf values in a pandas data frame\n",
    "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vect.get_feature_names(), columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf = Pipeline([('vect', tfidf_vect),\n",
    "               ('clf', MultinomialNB(alpha=0.05)),\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_count = Pipeline([('vect', count_vect),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf.fit(train_df['text'], train_df['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_count.fit(train_df['text'], train_df['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist_text_test = glob.glob(f\"{cy24}/training_corpus/*training.txt\")\n",
    "flist_label_test = glob.glob(f\"{cy24}/training_corpus/*_Scientific_Category.txt\")\n",
    "test_df, data = pacman2020.read_in_dataset(flist_text=flist_text_test, flist_label=flist_label_test, notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category_id'] = test_df['category'].factorize()[0]\n",
    "category_id_df_test = test_df[['category','category_id']]\n",
    "category_to_id_test = dict(category_id_df_test.values)\n",
    "id_to_category_test = dict(category_id_df_test[['category_id', 'category']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_category_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_category_test[0] = 'stellar populations and the ism'\n",
    "id_to_category_test[1] = id_to_category_test[1].lower() \n",
    "id_to_category_test[2] = id_to_category_test[2].lower()\n",
    "id_to_category_test[3] = 'planets and planet formation'\n",
    "id_to_category_test[4] = 'galaxies and the igm'\n",
    "id_to_category_test[5] = 'large scale structure of the universe'\n",
    "id_to_category_test[6] = 'supermassive black holes and active galaxies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb_tfidf.predict(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_df['category_id'], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_count = nb_count.predict(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_df['category_id'], predictions_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(test_df['category_id'], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat_count = confusion_matrix(test_df['category_id'], predictions_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_mat_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_df['category_id'], predictions_count , target_names=list(id_to_category_test.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_df['category_id'], predictions , target_names=list(id_to_category_test.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle 25 testing using the UAT categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_classifications = pd.read_csv('/Users/nmiles/PACMan_dist/cycle_25_classifications.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the filenames to get the proposal number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_numbers = [int(val.split('/')[-1].split('_')[0]) for val in flist_text]\n",
    "flist_num = list(zip(flist_text, proposal_numbers))\n",
    "flist_num.sort(key=lambda val: val[1])\n",
    "flist_sorted, proposal_num = list(zip(*flist_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_classified_null = proposal_classifications[proposal_classifications['classification'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_classifications.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ediff1d(proposal_num)\n",
    "idx = list(map(int, np.where(a>1)[0]))\n",
    "missing_proposals = [proposal_num[val]+1 for val in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_classified_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_classifications['fname'] = [np.nan]*len(proposal_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_classifications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, fname in zip(proposal_num, flist_sorted, ):\n",
    "    proposal_classifications['fname'].loc[num-1] = fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_classifications['classification'].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, data = pacman2020.read_in_dataset(flist_label=flist_label, flist_text=flist_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
