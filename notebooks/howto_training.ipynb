{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# native python\n",
    "import os\n",
    "import sys\n",
    "from os import path\n",
    "cwd = os.getcwd()\n",
    "os.chdir(path.abspath(path.join(os.getcwd(),\"..\")))\n",
    "\n",
    "# open source packages\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# custom packages that are all in the github repo\n",
    "from pacman_classes import PACManTrain, PACManPipeline\n",
    "from utils.proposal_scraper import ProposalScraper\n",
    "from utils.analyzer import PACManAnalyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Proposal Scraping\n",
    "We use the `ProposalScraper` class contained in the `proposal_scraper` module in the `utils` subpackage. We specify that we are scraping the proposals with the intention of using them for training and that we only want to scrape proposals in Cycle 24.\n",
    "- By setting `for_training=True`, the software automatically looks for a file containing the hand classifications for the list of proposals and saves the scraped proposal information in an subdirectory of `~/PACMan_dist/training_data/`. In this example, the subdirectory will be named `training_corpus_cy24` and it will contain all of the training data for the given cycle, as well as the file containing the hand classifications.\n",
    "- For the hand classifications, we adopt the following naming convention: cycle_CYCLENUMBER_hand_classifications.txt\n",
    "   - e.g. cycle_24_hand_classifications.txt contains the hand classification of each proposal for cycle 24.\n",
    "- Additionally, the file should only contain two columns, `proposal_num` and `hand_classification`. Below is an example snippet of what the file should look like:\n",
    "    \n",
    "```console\n",
    "\n",
    "proposal_num,hand_classification\n",
    "0001,stellar physics\n",
    "0002,stellar physics\n",
    "        .\n",
    "        . \n",
    "        .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an instance of the proposal scraping and scrape each cycle\n",
    "pacman_scraper = ProposalScraper(for_training=True, cycles_to_analyze=[24, 25])\n",
    "pacman_scraper.scrape_cycles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text Preprocessing (it could be a while... )\n",
    "The `PACManTrain` class contained in the `pacman2020` module to is capable of performing all of the necessary preprocessing steps. Just like before, we specify the cycles we want to analyze and in this case it is just cycle 24.\n",
    "\n",
    "In summary, this step is processing each input proposal with the `spaCy` NLP package to generate a `Doc` object, which is a sequence of tokens. Each token is an individual word that contains a variety of semantic information derived from the word and its context in a sentence. We leverage this information to filter out stop words, punctuations,  etc... This is the slowest step of the entire process and if needed, it can be improved using the multithreading behavior of `spaCy`.\n",
    "\n",
    "The text preprocessing steps taken about 11 minutes per cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_training = PACManTrain(cycles_to_analyze=[24, 25])\n",
    "pacman_training.read_training_data(parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each proposal cycle in the `cycle_to_analyze` argument, the tokenizer will perform the necessary preprocessing steps and save the proposal number, text, cleaned text, filename, the hand classified science category, and the encoded value of the hand classified category. The results are stored in a pandas DataFrame in the `PACManTrain.proposal_data` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found proposal information for:\\n'+'\\n'.join(pacman_training.proposal_data.keys())+'\\n')\n",
    "\n",
    "# Print the first 5 rows of the DataFrame for cycle 24\n",
    "for key in pacman_training.proposal_data.keys():\n",
    "    print(f\"Displaying some information for {key}...\")\n",
    "    print(pacman_training.proposal_data[key].info())\n",
    "    print('-'*58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the first proposal in the Cycle 24 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = pacman_training.proposal_data['Cycle24'].iloc[0]\n",
    "msg = (\n",
    "    f\"HST Cycle 24 proposal number: {first_row['proposal_num']}\\n\"\n",
    "    f\"Hand Classification: {first_row['hand_classification']}\\n\"\n",
    "    f\"Raw Text:\\n{first_row['text'][:100]}...\\n\"\n",
    "    f\"Cleaned Text:\\n{first_row['cleaned_text'][:100]}...\\n\"\n",
    "\n",
    ")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side note: pandas is cool.\n",
    "\n",
    "We can use the resulting DataFrame to quickly examine the distribution of proposal categories for each cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(5,7), gridspec_kw={'hspace':0.3})\n",
    "for i, key in enumerate(pacman_training.proposal_data.keys()):\n",
    "    proposal_categories = pacman_training.proposal_data[key]['hand_classification'].value_counts()\n",
    "    proposal_categories.sort_index(inplace=True)\n",
    "    ax = proposal_categories.plot.barh(label=key, ax=axes[i])\n",
    "    ax.set_title(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training\n",
    "\n",
    "Now that we have all the proposal information loaded, we can train a classifier. When no model or vectorizer is specified, the software will use the default classifier (Multinomial Naive Bayes) and the default vectorizer (term frequency-inverse document frequency TFIDF). In theory, you can pass any combination of vectorizer and classifier that you want!\n",
    "\n",
    "We test on cycle 25 because the original work was evaluated on cycle 24 data and these are the only two proposal cycles we have that have been hand classified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_training.fit_model(pacman_training.proposal_data[\"Cycle25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pacman_training.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Testing \n",
    "Finally, we evaluate the performance of the model we just trained. To do so, we use it to make predictions on a completely different proposal cycle that has also been hand classified. We compare the predictions to the hand classifications and voila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_training.apply_model(df=pacman_training.proposal_data[\"Cycle24\"], training=True)\n",
    "print(\"scikit-learn classification report\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true = pacman_training.model_results['encoded_hand_classification'],\n",
    "        y_pred = pacman_training.model_results['encoded_model_classification'],\n",
    "        target_names=pacman_training.encoder.classes_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the analysis class to compute our customized accuracy to allow for a comparison with the previous package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_analyzing = PACManAnalyze()\n",
    "pacman_analyzing.encoder = pacman_training.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_analyzing.compute_accuracy_measurements(df=pacman_training.model_results, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"computed accuracy: {pacman_analyzing.computed_accuracy['top'].sum()/pacman_analyzing.computed_accuracy.sum().sum():.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_analyzing.cycle=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_analyzing.plot_barh(100*pacman_analyzing.computed_accuracy.loc[:,['top','top_two','misclassified']], fout='test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the results and model\n",
    "\n",
    "To provide a means of benchmarking various models, the classes have the functionality for saving the model results, as well as the trained model. By passing the `training=True` in the cell below, we are telling the code to save the results in the training subdirectory of the results directory. When `training=False` is passed, the results are written to the production directory. The intention here is to keep the results from training separate from the results when new proposals are analyzed. The path to each directory is given below:       \n",
    "    \n",
    "- ~/PACMan_dist/model_results/training/      \n",
    "- ~/PACMan_dist/model_results/production/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacman_training.save_model_results(fout='example_pacmaproposal_datacycle24.txt')#, training=True)\n",
    "pacman_training.save_model(fname='example_pacman_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
